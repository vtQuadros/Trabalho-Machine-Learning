{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac51e739",
   "metadata": {},
   "source": [
    "# Projeto Machine Learning - Predi√ß√£o de Acidentes A√©reos Fatais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e969e1",
   "metadata": {},
   "source": [
    "## Sum√°rio do Projeto: Predi√ß√£o de Acidentes A√©reos Fatais\n",
    "\n",
    "### 1. Introdu√ß√£o e Objetivos\n",
    "#### 1.1. Contexto do Problema\n",
    "#### 1.2. Objetivos da An√°lise\n",
    "- An√°lise Explorat√≥ria\n",
    "- Engenharia de Features\n",
    "- Modelagem Preditiva\n",
    "- Valida√ß√£o\n",
    "#### 1.3. Dicion√°rio de Vari√°veis\n",
    "\n",
    "### 2. Configura√ß√£o do Ambiente\n",
    "\n",
    "### 3. Carga e An√°lise Inicial dos Dados\n",
    "\n",
    "### 4. Limpeza e Pr√©-Processamento dos Dados\n",
    "#### 4.1. Remo√ß√£o de Duplicatas\n",
    "#### 4.2. Tratamento de Tipos de Dados\n",
    "#### 4.3. Tratamento de Valores Ausentes (Nulos)\n",
    "- Preenchimento com mediana (num√©ricos)\n",
    "- Preenchimento com moda (categ√≥ricos)\n",
    "- Remo√ß√£o de linhas cr√≠ticas\n",
    "\n",
    "### 5. An√°lise Explorat√≥ria de Dados (EDA)\n",
    "#### 5.1. Distribui√ß√£o Geogr√°fica dos Acidentes\n",
    "#### 5.2. An√°lise Temporal\n",
    "#### 5.3. Balanceamento das Classes\n",
    "\n",
    "### 6. Engenharia e Sele√ß√£o de Features\n",
    "#### 6.1. Cria√ß√£o de Features Temporais\n",
    "#### 6.2. Separa√ß√£o de Features Num√©ricas e Categ√≥ricas\n",
    "#### 6.3. Prepara√ß√£o dos Dados para Modelagem\n",
    "\n",
    "### 7. Modelagem\n",
    "#### 7.1. Divis√£o Treino/Teste\n",
    "#### 7.2. Encoding e Normaliza√ß√£o\n",
    "#### 7.3. Balanceamento com SMOTE\n",
    "#### 7.4. Treinamento dos Modelos\n",
    "- Modelo Baseline (Dummy)\n",
    "- Regress√£o Log√≠stica\n",
    "- √Årvore de Decis√£o\n",
    "\n",
    "### 8. Valida√ß√£o e Compara√ß√£o dos Modelos\n",
    "#### 8.1. M√©tricas de Performance\n",
    "#### 8.2. Matrizes de Confus√£o\n",
    "#### 8.3. Curva ROC e AUC\n",
    "\n",
    "### 9. Otimiza√ß√£o e Avalia√ß√£o Final\n",
    "#### 9.1. An√°lise de Threshold\n",
    "#### 9.2. Compara√ß√£o Final dos Modelos\n",
    "#### 9.3. Import√¢ncia das Features\n",
    "\n",
    "### 10. Conclus√µes e Pr√≥ximos Passos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f898c",
   "metadata": {},
   "source": [
    "## Alunos:\n",
    "- **Eduardo**\n",
    "\n",
    "\n",
    "##### Link do projeto no GitHub: https://github.com/vtQuadros/Trabalho-Machine-Learning\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47152c",
   "metadata": {},
   "source": [
    "## 1. Introdu√ß√£o e Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ac5b8",
   "metadata": {},
   "source": [
    "### 1.1 Contexto do Problema\n",
    "\n",
    "A seguran√ßa a√©rea √© uma preocupa√ß√£o fundamental no setor de avia√ß√£o. Identificar padr√µes que levam a acidentes fatais pode ajudar autoridades, companhias a√©reas e √≥rg√£os reguladores a tomar medidas preventivas e salvar vidas.\n",
    "\n",
    "Este projeto foca em analisar dados hist√≥ricos de acidentes a√©reos no Brasil (CENIPA) para construir um modelo preditivo capaz de determinar se um acidente ser√° fatal ou n√£o-fatal com base em caracter√≠sticas do voo, aeronave e condi√ß√µes do acidente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a3f2",
   "metadata": {},
   "source": [
    "### 1.2 Objetivos da An√°lise\n",
    "\n",
    "- **1.** **An√°lise Explorat√≥ria**: Entender os padr√µes de acidentes a√©reos, identificando distribui√ß√µes geogr√°ficas, temporais e caracter√≠sticas das aeronaves envolvidas.\n",
    "- **2.** **Engenharia de Features**: Criar vari√°veis que ajudem a identificar o risco de fatalidade, incluindo features temporais e categ√≥ricas.\n",
    "- **3.** **Modelagem Preditiva**: Treinar e avaliar diferentes modelos de Machine Learning (Baseline, Regress√£o Log√≠stica e √Årvore de Decis√£o) para prever a probabilidade de um acidente ser fatal.\n",
    "- **4.** **Valida√ß√£o**: Avaliar os modelos usando m√∫ltiplas m√©tricas (Acur√°cia, Precis√£o, Recall, F1-Score, AUC-ROC) e otimizar o threshold de decis√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f893dc2",
   "metadata": {},
   "source": [
    "### 1.3 Dicion√°rio de Vari√°veis\n",
    "\n",
    "O conjunto de dados cont√©m informa√ß√µes sobre acidentes a√©reos no Brasil. As principais vari√°veis incluem:\n",
    "\n",
    "**Vari√°veis Geogr√°ficas:**\n",
    "- **latitude/longitude**: Coordenadas do local do acidente\n",
    "- **regiao**: Regi√£o do Brasil (Norte, Sul, Nordeste, etc.)\n",
    "- **uf**: Unidade Federativa\n",
    "\n",
    "**Vari√°veis Temporais:**\n",
    "- **dt_ocorrencia**: Data do acidente\n",
    "- **hr_ocorrencia**: Hora do acidente\n",
    "- **ano_ocorrencia**: Ano extra√≠do da data\n",
    "- **mes_ocorrencia**: M√™s extra√≠do da data\n",
    "\n",
    "**Caracter√≠sticas da Aeronave:**\n",
    "- **modelo_aeronave**: Modelo da aeronave\n",
    "- **nome_fabricante**: Fabricante da aeronave\n",
    "- **cat_aeronave**: Categoria da aeronave\n",
    "- **peso_max_decolagem**: Peso m√°ximo de decolagem\n",
    "- **numero_assentos**: N√∫mero de assentos\n",
    "\n",
    "**Vari√°veis Operacionais:**\n",
    "- **fase_operacao**: Fase do voo (decolagem, cruzeiro, pouso, etc.)\n",
    "- **op_padronizado**: Opera√ß√£o padronizada\n",
    "\n",
    "**Vari√°vel Target:**\n",
    "- **les_fatais_trip**: 1 = Fatal, 0 = N√£o Fatal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898e614",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o do Ambiente\n",
    "\n",
    "Nesta se√ß√£o, importamos todas as bibliotecas necess√°rias para a an√°lise, pr√©-processamento e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8eb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para manipula√ß√£o e an√°lise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotecas para visualiza√ß√£o de dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas de Machine Learning e pr√©-processamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# Balanceamento de classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44903ac",
   "metadata": {},
   "source": [
    "## 3. Carga e An√°lise Inicial dos Dados\n",
    "\n",
    "Carregamos os dados de treino e realizamos uma verifica√ß√£o inicial para entender sua estrutura, tipos de dados e a presen√ßa de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa72bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset de treino\n",
    "df = pd.read_csv(\"docs/treino.csv\")\n",
    "\n",
    "print(f\"‚úì Dados carregados com sucesso!\")\n",
    "print(f\"Dimens√µes: {df.shape[0]} linhas x {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96530d5d",
   "metadata": {},
   "source": [
    "### An√°lise Inicial:\n",
    "- O dataset possui m√∫ltiplas linhas e colunas com informa√ß√µes sobre acidentes a√©reos\n",
    "- H√° colunas geogr√°ficas (latitude, longitude, regiao, uf)\n",
    "- Colunas temporais (dt_ocorrencia, hr_ocorrencia)\n",
    "- Caracter√≠sticas das aeronaves (modelo, fabricante, peso, assentos)\n",
    "- Vari√°vel target: les_fatais_trip (0 = N√£o Fatal, 1 = Fatal)\n",
    "- Presen√ßa de valores nulos que precisar√£o de tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostra dos dados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a estrutura e os tipos de dados do DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092fd2a4",
   "metadata": {},
   "source": [
    "## 4. Limpeza e Pr√©-Processamento dos Dados\n",
    "\n",
    "Esta etapa √© crucial para garantir a qualidade dos dados que alimentar√£o o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d38616",
   "metadata": {},
   "source": [
    "### 4.1 Remo√ß√£o de Duplicatas\n",
    "\n",
    "Removemos registros duplicados que podem distorcer a an√°lise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ab8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando informa√ß√µes antes da remo√ß√£o\n",
    "print(\"Antes da remo√ß√£o de duplicatas:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicatas\n",
    "linhas_antes = len(df)\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "linhas_depois = len(df)\n",
    "\n",
    "print(f\"Linhas antes: {linhas_antes}\")\n",
    "print(f\"Linhas depois: {linhas_depois}\")\n",
    "print(f\"‚úì Duplicatas removidas: {linhas_antes - linhas_depois}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3297f6",
   "metadata": {},
   "source": [
    "### 4.2 Tratamento de Tipos de Dados\n",
    "\n",
    "Convertemos colunas para os tipos apropriados (datas, num√©ricos, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter latitude e longitude para float\n",
    "df['latitude'] = df['latitude'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['longitude'] = df['longitude'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "# Converter data\n",
    "df['dt_ocorrencia'] = pd.to_datetime(df['dt_ocorrencia'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "print(\"Convers√µes realizadas!\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef4841",
   "metadata": {},
   "source": [
    "### 4.3 Tratamento de Valores Ausentes (Nulos)\n",
    "\n",
    "- **Preenchimento com mediana**: Para colunas num√©ricas\n",
    "- **Preenchimento com moda**: Para colunas categ√≥ricas\n",
    "- **Remo√ß√£o de linhas**: Para dados essenciais ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff948518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes - num√©ricos com mediana\n",
    "df['peso_max_decolagem'].fillna(df['peso_max_decolagem'].median(), inplace=True)\n",
    "df['numero_assentos'].fillna(df['numero_assentos'].median(), inplace=True)\n",
    "\n",
    "# Preencher valores ausentes - categ√≥ricos com moda\n",
    "df['op_padronizado'].fillna(df['op_padronizado'].mode()[0], inplace=True)\n",
    "df['hr_ocorrencia'].fillna(df['hr_ocorrencia'].mode()[0], inplace=True)\n",
    "df['regiao'].fillna(df['regiao'].mode()[0], inplace=True)\n",
    "df['fase_operacao'].fillna(df['fase_operacao'].mode()[0], inplace=True)\n",
    "df['modelo_aeronave'].fillna(df['modelo_aeronave'].mode()[0], inplace=True)\n",
    "df['nome_fabricante'].fillna(df['nome_fabricante'].mode()[0], inplace=True)\n",
    "\n",
    "# Remover linhas com dados essenciais ausentes\n",
    "df.dropna(subset=['dt_ocorrencia', 'latitude', 'longitude'], inplace=True)\n",
    "\n",
    "print(\"Tratamento de valores ausentes conclu√≠do!\")\n",
    "print(f\"Total de linhas ap√≥s tratamento: {len(df)}\")\n",
    "print(\"\\nValores nulos restantes:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novas colunas de ano e m√™s\n",
    "df['ano_ocorrencia'] = df['dt_ocorrencia'].dt.year\n",
    "df['mes_ocorrencia'] = df['dt_ocorrencia'].dt.month\n",
    "\n",
    "print(\"Novas colunas criadas!\")\n",
    "df[['dt_ocorrencia', 'ano_ocorrencia', 'mes_ocorrencia']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento dos valores (NaN)\n",
    "\n",
    "print(\"\\n--- Contagem de valores nulos ANTES do tratamento ---\")\n",
    "\n",
    "\n",
    "# Lista de colunas num√©ricas para imputar com a mediana\n",
    "colunas_numericas_nan = ['peso_max_decolagem', 'numero_assentos']\n",
    "for col in colunas_numericas_nan:\n",
    "    mediana = df[col].median()\n",
    "    df[col] = df[col].fillna(mediana)\n",
    "    print(f\"Valores nulos em '{col}' preenchidos com a mediana: {mediana}\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Lista de colunas categ√≥ricas para imputar com a moda\n",
    "colunas_categoricas_nan = ['op_padronizado', 'hr_ocorrencia', 'regiao', 'fase_operacao', 'modelo_aeronave', 'nome_fabricante']\n",
    "for col in colunas_categoricas_nan:\n",
    "    moda = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(moda)\n",
    "    print(f\"Valores nulos em '{col}' preenchidos com a moda: '{moda}'\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Removendo linhas onde dados essenciais ainda s√£o nulos\n",
    "print(\"Removendo linhas onde 'dt_ocorrencia', 'latitude' ou 'longitude' s√£o nulos...\")\n",
    "df.dropna(subset=['dt_ocorrencia', 'latitude', 'longitude'], inplace=True)\n",
    "\n",
    "print(\"\\n--- Contagem de valores nulos DEPOIS do tratamento ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12316300",
   "metadata": {},
   "source": [
    "## 5. An√°lise Explorat√≥ria de Dados (EDA)\n",
    "\n",
    "### 5.1 Sele√ß√£o de Features e Visualiza√ß√£o da Distribui√ß√£o da Vari√°vel Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar features e target\n",
    "features = ['latitude', 'longitude', 'peso_max_decolagem', 'numero_assentos',\n",
    "            'fase_operacao', 'cat_aeronave', 'regiao', 'uf', 'modelo_aeronave', \n",
    "            'nome_fabricante', 'ano_ocorrencia', 'mes_ocorrencia']\n",
    "\n",
    "X = df[features]\n",
    "y = df['les_fatais_trip']\n",
    "\n",
    "print(f\"Features selecionadas: {X.shape[1]}\")\n",
    "print(f\"Total de registros: {X.shape[0]}\")\n",
    "\n",
    "# Verificar balanceamento\n",
    "print(\"\\nDistribui√ß√£o da vari√°vel target:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Visualizar balanceamento\n",
    "plt.figure(figsize=(8, 5))\n",
    "y.value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Acidentes Fatais vs N√£o Fatais')\n",
    "plt.xlabel('Classe (0=N√£o Fatal, 1=Fatal)')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af12f2f",
   "metadata": {},
   "source": [
    "## 6. Engenharia e Sele√ß√£o de Features\n",
    "\n",
    "### 6.1 Divis√£o dos Dados (Treino/Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treino: {len(X_train)} linhas\")\n",
    "print(f\"Conjunto de teste: {len(X_test)} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bac136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar colunas num√©ricas e categ√≥ricas\n",
    "colunas_numericas = ['latitude', 'longitude', 'peso_max_decolagem', 'numero_assentos', \n",
    "                     'ano_ocorrencia', 'mes_ocorrencia']\n",
    "colunas_categoricas = ['fase_operacao', 'cat_aeronave', 'regiao', 'uf', \n",
    "                       'modelo_aeronave', 'nome_fabricante']\n",
    "\n",
    "print(\"Colunas num√©ricas:\", colunas_numericas)\n",
    "print(\"Colunas categ√≥ricas:\", colunas_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632fd1a",
   "metadata": {},
   "source": [
    "### 6.2 Separa√ß√£o de Features por Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar vari√°veis categ√≥ricas com get_dummies\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=colunas_categoricas)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=colunas_categoricas)\n",
    "\n",
    "# Garantir que treino e teste tenham as mesmas colunas\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "print(f\"Features ap√≥s encoding: {X_train_encoded.shape[1]}\")\n",
    "\n",
    "# Normalizar features num√©ricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "print(\"Pr√©-processamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f3df6",
   "metadata": {},
   "source": [
    "### 6.3 Encoding e Normaliza√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbc032",
   "metadata": {},
   "source": [
    "## 7. Modelagem\n",
    "\n",
    "### 7.1 Balanceamento de Classes com SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dee68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear as classes\n",
    "print(\"Antes do SMOTE:\")\n",
    "print(f\"Classe 0 (N√£o Fatal): {sum(y_train == 0)}\")\n",
    "print(f\"Classe 1 (Fatal): {sum(y_train == 1)}\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nDepois do SMOTE:\")\n",
    "print(f\"Classe 0 (N√£o Fatal): {sum(y_train_balanced == 0)}\")\n",
    "print(f\"Classe 1 (Fatal): {sum(y_train_balanced == 1)}\")\n",
    "\n",
    "# Visualizar balanceamento\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "pd.Series(y_train).value_counts().plot(kind='bar', ax=axes[0], color=['skyblue', 'salmon'])\n",
    "axes[0].set_title('Antes do SMOTE')\n",
    "axes[0].set_xlabel('Classe')\n",
    "axes[0].set_ylabel('Quantidade')\n",
    "\n",
    "pd.Series(y_train_balanced).value_counts().plot(kind='bar', ax=axes[1], color=['lightgreen', 'lightcoral'])\n",
    "axes[1].set_title('Depois do SMOTE')\n",
    "axes[1].set_xlabel('Classe')\n",
    "axes[1].set_ylabel('Quantidade')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95129ad",
   "metadata": {},
   "source": [
    "### 7.2 Treinamento dos Modelos\n",
    "\n",
    "Treinamos tr√™s modelos para compara√ß√£o:\n",
    "- **Baseline (Dummy)**: Modelo simples de refer√™ncia\n",
    "- **Regress√£o Log√≠stica**: Modelo linear com dados balanceados\n",
    "- **√Årvore de Decis√£o**: Modelo n√£o-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar os modelos\n",
    "\n",
    "# 1. Modelo Baseline (Dummy)\n",
    "modelo_baseline = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "modelo_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 2. Regress√£o Log√≠stica com dados balanceados\n",
    "modelo_logistica = LogisticRegression(random_state=42, max_iter=1000)\n",
    "modelo_logistica.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# 3. √Årvore de Decis√£o\n",
    "modelo_arvore = DecisionTreeClassifier(random_state=42)\n",
    "modelo_arvore.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Modelos treinados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predi√ß√µes\n",
    "y_pred_baseline = modelo_baseline.predict(X_test_scaled)\n",
    "y_pred_logistica = modelo_logistica.predict(X_test_scaled)\n",
    "y_pred_arvore = modelo_arvore.predict(X_test_scaled)\n",
    "\n",
    "# Calcular m√©tricas para cada modelo\n",
    "modelos = ['Baseline', 'Regress√£o Log√≠stica', '√Årvore de Decis√£o']\n",
    "predicoes = [y_pred_baseline, y_pred_logistica, y_pred_arvore]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESULTADOS DOS MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for nome, y_pred in zip(modelos, predicoes):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{nome}:\")\n",
    "    print(f\"  Acur√°cia:  {acc:.4f}\")\n",
    "    print(f\"  Precis√£o:  {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279a8b0",
   "metadata": {},
   "source": [
    "### 7.3 Predi√ß√µes e M√©tricas Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf90f9d",
   "metadata": {},
   "source": [
    "## 8. Valida√ß√£o e Compara√ß√£o dos Modelos\n",
    "\n",
    "### 8.1 Matrizes de Confus√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27489b05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41177aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o - Regress√£o Log√≠stica\n",
    "print(\"Matriz de Confus√£o - Regress√£o Log√≠stica\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logistica, cmap='Blues')\n",
    "plt.title('Matriz de Confus√£o - Regress√£o Log√≠stica')\n",
    "plt.show()\n",
    "\n",
    "# Matriz de Confus√£o - √Årvore de Decis√£o\n",
    "print(\"\\nMatriz de Confus√£o - √Årvore de Decis√£o\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_arvore, cmap='Greens')\n",
    "plt.title('Matriz de Confus√£o - √Årvore de Decis√£o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a751c7",
   "metadata": {},
   "source": [
    "As matrizes de confus√£o mostram os acertos e erros de cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Calcular AUC para cada modelo\n",
    "auc_logistica = roc_auc_score(y_test, modelo_logistica.predict_proba(X_test_scaled)[:, 1])\n",
    "auc_arvore = roc_auc_score(y_test, modelo_arvore.predict_proba(X_test_scaled)[:, 1])\n",
    "\n",
    "# Plotar curvas\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    modelo_logistica.predict_proba(X_test_scaled)[:, 1], \n",
    "    name=f'Regress√£o Log√≠stica (AUC = {auc_logistica:.3f})', \n",
    "    ax=ax,\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    modelo_arvore.predict_proba(X_test_scaled)[:, 1], \n",
    "    name=f'√Årvore de Decis√£o (AUC = {auc_arvore:.3f})', \n",
    "    ax=ax,\n",
    "    color='green'\n",
    ")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='red', label='Aleat√≥rio (AUC = 0.5)')\n",
    "plt.title('Curva ROC - Compara√ß√£o dos Modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Regress√£o Log√≠stica: {auc_logistica:.3f}\")\n",
    "print(f\"AUC √Årvore de Decis√£o: {auc_arvore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c34421",
   "metadata": {},
   "source": [
    "### 8.2 Curva ROC e AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca1505",
   "metadata": {},
   "source": [
    "## 9. Otimiza√ß√£o e Avalia√ß√£o Final\n",
    "\n",
    "### 9.1 An√°lise de Threshold (Limiar de Decis√£o)\n",
    "\n",
    "Por padr√£o, o modelo usa threshold de 0.5 para classificar. Vamos testar diferentes thresholds para otimizar o F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as probabilidades de predi√ß√£o\n",
    "y_proba = modelo_logistica.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Testando diferentes thresholds de 0.0 a 1.0...\")\n",
    "\n",
    "# Testando diferentes thresholds\n",
    "thresholds_results = {\n",
    "    'threshold': [],\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "\n",
    "for threshold in np.arange(0.0, 1.01, 0.01):\n",
    "    # Aplicando o threshold customizado\n",
    "    y_pred_threshold = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Calculando as m√©tricas\n",
    "    acc = accuracy_score(y_test, y_pred_threshold)\n",
    "    prec = precision_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    \n",
    "    # Armazenando os resultados\n",
    "    thresholds_results['threshold'].append(threshold)\n",
    "    thresholds_results['accuracy'].append(acc)\n",
    "    thresholds_results['precision'].append(prec)\n",
    "    thresholds_results['recall'].append(rec)\n",
    "    thresholds_results['f1_score'].append(f1)\n",
    "\n",
    "# Convertendo para DataFrame\n",
    "df_thresholds = pd.DataFrame(thresholds_results)\n",
    "\n",
    "# Encontrando o melhor threshold baseado no F1-Score\n",
    "melhor_threshold_idx = df_thresholds['f1_score'].idxmax()\n",
    "melhor_threshold = df_thresholds.loc[melhor_threshold_idx, 'threshold']\n",
    "melhor_f1 = df_thresholds.loc[melhor_threshold_idx, 'f1_score']\n",
    "\n",
    "print(f\"\\nMelhor threshold encontrado: {melhor_threshold:.2f}\")\n",
    "print(f\"F1-Score: {melhor_f1:.4f}\")\n",
    "print(f\"Accuracy: {df_thresholds.loc[melhor_threshold_idx, 'accuracy']:.4f}\")\n",
    "print(f\"Precision: {df_thresholds.loc[melhor_threshold_idx, 'precision']:.4f}\")\n",
    "print(f\"Recall: {df_thresholds.loc[melhor_threshold_idx, 'recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 melhores thresholds por F1-Score:\")\n",
    "print(df_thresholds.nlargest(5, 'f1_score')[['threshold', 'f1_score', 'accuracy', 'precision', 'recall']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3482af4",
   "metadata": {},
   "source": [
    "### 9.2 Visualiza√ß√£o do Impacto do Threshold\n",
    "\n",
    "Vamos visualizar graficamente como o threshold afeta as diferentes m√©tricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfe03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o gr√°fico de impacto do threshold\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plotando as curvas de m√©tricas\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['accuracy'], \n",
    "         label='Acur√°cia', linewidth=2, color='blue', alpha=0.7)\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['precision'], \n",
    "         label='Precis√£o', linewidth=2, color='green', alpha=0.7)\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['recall'], \n",
    "         label='Recall', linewidth=2, color='orange', alpha=0.7)\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['f1_score'], \n",
    "         label='F1-Score', linewidth=2.5, color='red', alpha=0.9)\n",
    "\n",
    "# Marcando o melhor threshold\n",
    "plt.axvline(x=melhor_threshold, color='purple', linestyle='--', linewidth=2, \n",
    "            label=f'Melhor Threshold ({melhor_threshold:.2f})')\n",
    "plt.scatter([melhor_threshold], [melhor_f1], color='purple', s=200, zorder=5, \n",
    "            marker='*', edgecolors='black', linewidths=1.5)\n",
    "\n",
    "# Configura√ß√µes do gr√°fico\n",
    "plt.xlabel('Threshold (Limiar de Decis√£o)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Score das M√©tricas', fontsize=12, fontweight='bold')\n",
    "plt.title('Impacto do Threshold nas M√©tricas de Avalia√ß√£o\\n(Trade-off entre Precis√£o e Recall)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpreta√ß√£o dos resultados\n",
    "print(\"\\nüìñ INTERPRETA√á√ÉO DO GR√ÅFICO:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. PRECIS√ÉO (linha verde):\")\n",
    "print(\"   - Aumenta conforme o threshold aumenta\")\n",
    "print(\"   - Threshold alto = menos falsos positivos = maior precis√£o\")\n",
    "print(\"   - Use threshold alto quando o custo de falsos positivos √© alto\")\n",
    "\n",
    "print(\"\\n2. RECALL (linha laranja):\")\n",
    "print(\"   - Diminui conforme o threshold aumenta\")\n",
    "print(\"   - Threshold baixo = menos falsos negativos = maior recall\")\n",
    "print(\"   - Use threshold baixo quando o custo de falsos negativos √© alto\")\n",
    "\n",
    "print(\"\\n3. F1-SCORE (linha vermelha - MAIS IMPORTANTE):\")\n",
    "print(\"   - Equilibra Precis√£o e Recall\")\n",
    "print(f\"   - Pico em threshold = {melhor_threshold:.2f}\")\n",
    "print(\"   - √â o melhor ponto de equil√≠brio entre as duas m√©tricas\")\n",
    "\n",
    "print(\"\\n4. TRADE-OFF:\")\n",
    "print(\"   - O gr√°fico mostra claramente o trade-off entre Precis√£o e Recall\")\n",
    "print(\"   - N√£o podemos maximizar ambos simultaneamente\")\n",
    "print(f\"   - O threshold √≥timo ({melhor_threshold:.2f}) balanceia ambos\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13e9af",
   "metadata": {},
   "source": [
    "### 9.3 Compara√ß√£o Final dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e0799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando threshold otimizado\n",
    "y_pred_logistica_threshold = (y_proba >= melhor_threshold).astype(int)\n",
    "\n",
    "# Comparando m√©tricas dos modelos\n",
    "metricas = {\n",
    "    'Modelo': ['Baseline (Dummy)', 'Regress√£o Log√≠stica', '√Årvore de Decis√£o'],\n",
    "    'Acur√°cia': [\n",
    "        accuracy_score(y_test, y_pred_baseline), \n",
    "        accuracy_score(y_test, y_pred_logistica_threshold),\n",
    "        accuracy_score(y_test, y_pred_arvore)\n",
    "    ],\n",
    "    'Precis√£o': [\n",
    "        precision_score(y_test, y_pred_baseline, zero_division=0), \n",
    "        precision_score(y_test, y_pred_logistica_threshold, zero_division=0),\n",
    "        precision_score(y_test, y_pred_arvore, zero_division=0)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_baseline, zero_division=0), \n",
    "        recall_score(y_test, y_pred_logistica_threshold, zero_division=0),\n",
    "        recall_score(y_test, y_pred_arvore, zero_division=0)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, y_pred_baseline, zero_division=0), \n",
    "        f1_score(y_test, y_pred_logistica_threshold, zero_division=0),\n",
    "        f1_score(y_test, y_pred_arvore, zero_division=0)\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metricas = pd.DataFrame(metricas)\n",
    "\n",
    "# Mostrando resultados\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARA√á√ÉO DE M√âTRICAS DOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(df_metricas)\n",
    "\n",
    "# Encontrando o melhor modelo por F1-Score\n",
    "melhor_modelo_idx = df_metricas['F1-Score'].idxmax()\n",
    "print(f\"\\nMELHOR MODELO: {df_metricas.loc[melhor_modelo_idx, 'Modelo']}\")\n",
    "print(f\"F1-Score: {df_metricas.loc[melhor_modelo_idx, 'F1-Score']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Matriz de Confus√£o - Regress√£o Log√≠stica\n",
    "print(\"\\nMatriz de Confus√£o: Regress√£o Log√≠stica\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logistica_threshold, cmap='Blues')\n",
    "plt.title(f'Matriz de Confus√£o - Regress√£o Log√≠stica\\n(Threshold = {melhor_threshold:.2f})')\n",
    "plt.show()\n",
    "\n",
    "# Matriz de Confus√£o - √Årvore de Decis√£o\n",
    "print(\"\\nMatriz de Confus√£o: √Årvore de Decis√£o\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_arvore, cmap='Greens')\n",
    "plt.title('Matriz de Confus√£o - √Årvore de Decis√£o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo probabilidades\n",
    "y_proba_logistica = modelo_logistica.predict_proba(X_test_scaled)[:, 1]\n",
    "y_proba_arvore = modelo_arvore.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculando AUC\n",
    "auc_logistica = roc_auc_score(y_test, y_proba_logistica)\n",
    "auc_arvore = roc_auc_score(y_test, y_proba_arvore)\n",
    "\n",
    "# Plotando as curvas ROC\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    y_proba_logistica, \n",
    "    name=f'Regress√£o Log√≠stica (AUC = {auc_logistica:.3f})', \n",
    "    ax=ax,\n",
    "    color='blue',\n",
    "    linewidth=2.5\n",
    ")\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    y_proba_arvore, \n",
    "    name=f'√Årvore de Decis√£o (AUC = {auc_arvore:.3f})', \n",
    "    ax=ax,\n",
    "    color='green',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Linha de refer√™ncia\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='red', label='Classificador Aleat√≥rio (AUC = 0.5)', linewidth=2)\n",
    "\n",
    "plt.title('Curva ROC - Compara√ß√£o dos Modelos', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nINTERPRETA√á√ÉO DA CURVA ROC:\")\n",
    "print(\"- AUC pr√≥ximo de 1.0: Modelo excelente\")\n",
    "print(\"- AUC pr√≥ximo de 0.5: Modelo aleat√≥rio\")\n",
    "print(f\"- Regress√£o Log√≠stica: {auc_logistica:.3f}\")\n",
    "print(f\"- √Årvore de Decis√£o: {auc_arvore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be43d7bf",
   "metadata": {},
   "source": [
    "### 9.4 An√°lise Explorat√≥ria - Distribui√ß√£o Geogr√°fica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea40c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o Geogr√°fica dos Acidentes\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Gr√°fico 1: Mapa de dispers√£o de todos os acidentes\n",
    "scatter1 = axes[0].scatter(\n",
    "    df['longitude'], \n",
    "    df['latitude'], \n",
    "    c=df['les_fatais_trip'],\n",
    "    cmap='RdYlGn_r',  # Vermelho (fatal) para Verde (n√£o-fatal)\n",
    "    alpha=0.6,\n",
    "    s=50,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "axes[0].set_xlabel('Longitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Latitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('üó∫Ô∏è Distribui√ß√£o Geogr√°fica dos Acidentes A√©reos\\n(Brasil)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar legenda\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label('Fatalidade (0=N√£o Fatal, 1=Fatal)', rotation=270, labelpad=20)\n",
    "\n",
    "# Gr√°fico 2: Acidentes por Regi√£o\n",
    "acidentes_por_regiao = df.groupby(['regiao', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_por_regiao.plot(kind='bar', ax=axes[1], color=['lightgreen', 'crimson'], width=0.7)\n",
    "axes[1].set_xlabel('Regi√£o', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('N√∫mero de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('üìç Acidentes por Regi√£o e Gravidade', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(['N√£o Fatal', 'Fatal'], loc='upper right')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estat√≠sticas geogr√°ficas\n",
    "print(\"\\nüìä ESTAT√çSTICAS GEOGR√ÅFICAS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüó∫Ô∏è Total de acidentes: {len(df)}\")\n",
    "print(f\"\\nüìç Acidentes por regi√£o:\")\n",
    "for regiao in df['regiao'].value_counts().index:\n",
    "    total = len(df[df['regiao'] == regiao])\n",
    "    fatais = len(df[(df['regiao'] == regiao) & (df['les_fatais_trip'] == 1)])\n",
    "    taxa = (fatais/total)*100 if total > 0 else 0\n",
    "    print(f\"   {regiao}: {total} acidentes ({fatais} fatais - {taxa:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise Temporal dos Acidentes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Gr√°fico 1: Acidentes por Ano\n",
    "acidentes_ano = df.groupby(['ano_ocorrencia', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_ano.plot(kind='bar', ax=axes[0, 0], color=['lightgreen', 'crimson'], width=0.8)\n",
    "axes[0, 0].set_xlabel('Ano', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('N√∫mero de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('üìä Acidentes por Ano', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(['N√£o Fatal', 'Fatal'], loc='upper right')\n",
    "axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Tend√™ncia de Acidentes Fatais\n",
    "acidentes_fatais_ano = df[df['les_fatais_trip'] == 1].groupby('ano_ocorrencia').size()\n",
    "acidentes_totais_ano = df.groupby('ano_ocorrencia').size()\n",
    "taxa_fatalidade = (acidentes_fatais_ano / acidentes_totais_ano * 100).fillna(0)\n",
    "\n",
    "axes[0, 1].plot(taxa_fatalidade.index, taxa_fatalidade.values, marker='o', \n",
    "                linewidth=3, markersize=8, color='darkred')\n",
    "axes[0, 1].fill_between(taxa_fatalidade.index, taxa_fatalidade.values, alpha=0.3, color='red')\n",
    "axes[0, 1].set_xlabel('Ano', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Taxa de Fatalidade (%)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('üìà Tend√™ncia da Taxa de Fatalidade ao Longo dos Anos', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 3: Acidentes por M√™s\n",
    "acidentes_mes = df.groupby(['mes_ocorrencia', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_mes.plot(kind='bar', ax=axes[1, 0], color=['lightgreen', 'crimson'], width=0.8)\n",
    "axes[1, 0].set_xlabel('M√™s', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('N√∫mero de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('üìÜ Acidentes por M√™s (Sazonalidade)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(['N√£o Fatal', 'Fatal'], loc='upper right')\n",
    "meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
    "axes[1, 0].set_xticklabels(meses, rotation=45, ha='right')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Gr√°fico 4: Acidentes por Fase de Opera√ß√£o\n",
    "acidentes_fase = df.groupby(['fase_operacao', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_fase = acidentes_fase.nlargest(10, 1)  # Top 10 fases com mais fatais\n",
    "acidentes_fase.plot(kind='barh', ax=axes[1, 1], color=['lightgreen', 'crimson'])\n",
    "axes[1, 1].set_xlabel('N√∫mero de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Fase de Opera√ß√£o', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('‚úàÔ∏è Top 10 Fases de Opera√ß√£o Mais Cr√≠ticas', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(['N√£o Fatal', 'Fatal'], loc='lower right')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estat√≠sticas temporais\n",
    "print(\"\\nüìä ESTAT√çSTICAS TEMPORAIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÖ Per√≠odo analisado: {df['ano_ocorrencia'].min()} - {df['ano_ocorrencia'].max()}\")\n",
    "print(f\"\\nüìà Taxa m√©dia de fatalidade: {taxa_fatalidade.mean():.2f}%\")\n",
    "print(f\"\\nüî¥ Ano com maior taxa de fatalidade: {taxa_fatalidade.idxmax()} ({taxa_fatalidade.max():.2f}%)\")\n",
    "print(f\"üü¢ Ano com menor taxa de fatalidade: {taxa_fatalidade.idxmin()} ({taxa_fatalidade.min():.2f}%)\")\n",
    "print(f\"\\nüìÜ M√™s com mais acidentes: {meses[acidentes_mes.sum(axis=1).idxmax()-1]}\")\n",
    "print(f\"üìÜ M√™s com menos acidentes: {meses[acidentes_mes.sum(axis=1).idxmin()-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398af7f",
   "metadata": {},
   "source": [
    "### 9.5 An√°lise Explorat√≥ria - Padr√µes Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compara√ß√£o Visual dos Modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Preparar dados para visualiza√ß√£o\n",
    "modelos_nomes = ['Baseline\\n(Dummy)', 'Regress√£o\\nLog√≠stica', '√Årvore de\\nDecis√£o']\n",
    "cores_modelos = ['gray', 'green', 'orange']\n",
    "\n",
    "# Gr√°fico 1: Compara√ß√£o de Acur√°cia\n",
    "acuracias = df_metricas['Acur√°cia'].values\n",
    "bars1 = axes[0, 0].bar(range(len(modelos_nomes)), acuracias, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_ylabel('Acur√°cia', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Acur√°cia dos Modelos', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(range(len(modelos_nomes)))\n",
    "axes[0, 0].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acuracias[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gr√°fico 2: Compara√ß√£o de Precis√£o\n",
    "precisoes = df_metricas['Precis√£o'].values\n",
    "bars2 = axes[0, 1].bar(range(len(modelos_nomes)), precisoes, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].set_ylabel('Precis√£o', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Precis√£o dos Modelos', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(range(len(modelos_nomes)))\n",
    "axes[0, 1].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{precisoes[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gr√°fico 3: Compara√ß√£o de Recall\n",
    "recalls = df_metricas['Recall'].values\n",
    "bars3 = axes[1, 0].bar(range(len(modelos_nomes)), recalls, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_ylabel('Recall', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('Recall dos Modelos', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(range(len(modelos_nomes)))\n",
    "axes[1, 0].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars3):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{recalls[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gr√°fico 4: Compara√ß√£o de F1-Score\n",
    "f1_scores = df_metricas['F1-Score'].values\n",
    "bars4 = axes[1, 1].bar(range(len(modelos_nomes)), f1_scores, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('F1-Score dos Modelos (M√âTRICA PRINCIPAL)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xticks(range(len(modelos_nomes)))\n",
    "axes[1, 1].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars4):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{f1_scores[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    # Destacar o melhor modelo\n",
    "    if i == melhor_modelo_idx:\n",
    "        bar.set_edgecolor('gold')\n",
    "        bar.set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo estat√≠stico\n",
    "print(\"\\nRANKING DOS MODELOS (por F1-Score)\")\n",
    "print(\"=\"*70)\n",
    "ranking = df_metricas.sort_values('F1-Score', ascending=False)\n",
    "for idx, row in ranking.iterrows():\n",
    "    emoji = \"1¬∫\" if idx == 0 else \"2¬∫\" if idx == 1 else \"3¬∫\"\n",
    "    print(f\"{emoji} {row['Modelo']}\")\n",
    "    print(f\"   F1-Score: {row['F1-Score']:.4f} | Acur√°cia: {row['Acur√°cia']:.4f} | \"\n",
    "          f\"Precis√£o: {row['Precis√£o']:.4f} | Recall: {row['Recall']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543b9fa",
   "metadata": {},
   "source": [
    "### 9.6 Compara√ß√£o Visual dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de Import√¢ncia das Features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Gr√°fico 1: Import√¢ncia das Features - Regress√£o Log√≠stica\n",
    "# Usar coeficientes do modelo de Regress√£o Log√≠stica\n",
    "feature_names_encoded = X_train_encoded.columns.tolist()\n",
    "coeficientes = modelo_logistica.coef_[0]\n",
    "\n",
    "# Criar DataFrame com import√¢ncias\n",
    "importancias_log_df = pd.DataFrame({\n",
    "    'Feature': feature_names_encoded,\n",
    "    'Import√¢ncia': np.abs(coeficientes)  # Valor absoluto para ranking\n",
    "}).sort_values('Import√¢ncia', ascending=False).head(15)\n",
    "\n",
    "# Plotar\n",
    "axes[0].barh(range(len(importancias_log_df)), importancias_log_df['Import√¢ncia'], \n",
    "             color='green', edgecolor='black')\n",
    "axes[0].set_yticks(range(len(importancias_log_df)))\n",
    "axes[0].set_yticklabels(importancias_log_df['Feature'], fontsize=9)\n",
    "axes[0].set_xlabel('Import√¢ncia Absoluta (|Coeficiente|)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Top 15 Features - Regress√£o Log√≠stica', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Import√¢ncia das Features - √Årvore de Decis√£o\n",
    "importancias_arvore = modelo_arvore.feature_importances_\n",
    "\n",
    "importancias_arvore_df = pd.DataFrame({\n",
    "    'Feature': feature_names_encoded,\n",
    "    'Import√¢ncia': importancias_arvore\n",
    "}).sort_values('Import√¢ncia', ascending=False).head(15)\n",
    "\n",
    "axes[1].barh(range(len(importancias_arvore_df)), importancias_arvore_df['Import√¢ncia'], \n",
    "             color='orange', edgecolor='black')\n",
    "axes[1].set_yticks(range(len(importancias_arvore_df)))\n",
    "axes[1].set_yticklabels(importancias_arvore_df['Feature'], fontsize=9)\n",
    "axes[1].set_xlabel('Import√¢ncia (Gini)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Top 15 Features - √Årvore de Decis√£o', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo das features mais importantes\n",
    "print(\"\\nFEATURES MAIS IMPORTANTES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRegress√£o Log√≠stica (Top 5):\")\n",
    "for idx, row in importancias_log_df.head(5).iterrows():\n",
    "    print(f\"   {row['Feature']}: {row['Import√¢ncia']:.4f}\")\n",
    "\n",
    "print(\"\\n√Årvore de Decis√£o (Top 5):\")\n",
    "for idx, row in importancias_arvore_df.head(5).iterrows():\n",
    "    print(f\"   {row['Feature']}: {row['Import√¢ncia']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a36e32",
   "metadata": {},
   "source": [
    "### 9.7 Import√¢ncia das Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
