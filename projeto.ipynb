{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac51e739",
   "metadata": {},
   "source": [
    "# Projeto Machine Learning - Predição de Acidentes Aéreos Fatais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e969e1",
   "metadata": {},
   "source": [
    "## Sumário do Projeto: Predição de Acidentes Aéreos Fatais\n",
    "\n",
    "### 1. Introdução e Objetivos\n",
    "#### 1.1. Contexto do Problema\n",
    "#### 1.2. Objetivos da Análise\n",
    "- Análise Exploratória\n",
    "- Engenharia de Features\n",
    "- Modelagem Preditiva\n",
    "- Validação\n",
    "#### 1.3. Dicionário de Variáveis\n",
    "\n",
    "### 2. Configuração do Ambiente\n",
    "\n",
    "### 3. Carga e Análise Inicial dos Dados\n",
    "\n",
    "### 4. Limpeza e Pré-Processamento dos Dados\n",
    "#### 4.1. Remoção de Duplicatas\n",
    "#### 4.2. Tratamento de Tipos de Dados\n",
    "#### 4.3. Tratamento de Valores Ausentes (Nulos)\n",
    "- Preenchimento com mediana (numéricos)\n",
    "- Preenchimento com moda (categóricos)\n",
    "- Remoção de linhas críticas\n",
    "\n",
    "### 5. Análise Exploratória de Dados (EDA)\n",
    "#### 5.1. Distribuição Geográfica dos Acidentes\n",
    "#### 5.2. Análise Temporal\n",
    "#### 5.3. Balanceamento das Classes\n",
    "\n",
    "### 6. Engenharia e Seleção de Features\n",
    "#### 6.1. Criação de Features Temporais\n",
    "#### 6.2. Separação de Features Numéricas e Categóricas\n",
    "#### 6.3. Preparação dos Dados para Modelagem\n",
    "\n",
    "### 7. Modelagem\n",
    "#### 7.1. Divisão Treino/Teste\n",
    "#### 7.2. Encoding e Normalização\n",
    "#### 7.3. Balanceamento com SMOTE\n",
    "#### 7.4. Treinamento dos Modelos\n",
    "- Modelo Baseline (Dummy)\n",
    "- Regressão Logística\n",
    "- Árvore de Decisão\n",
    "\n",
    "### 8. Validação e Comparação dos Modelos\n",
    "#### 8.1. Métricas de Performance\n",
    "#### 8.2. Matrizes de Confusão\n",
    "#### 8.3. Curva ROC e AUC\n",
    "\n",
    "### 9. Otimização e Avaliação Final\n",
    "#### 9.1. Análise de Threshold\n",
    "#### 9.2. Comparação Final dos Modelos\n",
    "#### 9.3. Importância das Features\n",
    "\n",
    "### 10. Conclusões e Próximos Passos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f898c",
   "metadata": {},
   "source": [
    "## Alunos:\n",
    "- **Eduardo**\n",
    "\n",
    "\n",
    "##### Link do projeto no GitHub: https://github.com/vtQuadros/Trabalho-Machine-Learning\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47152c",
   "metadata": {},
   "source": [
    "## 1. Introdução e Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ac5b8",
   "metadata": {},
   "source": [
    "### 1.1 Contexto do Problema\n",
    "\n",
    "A segurança aérea é uma preocupação fundamental no setor de aviação. Identificar padrões que levam a acidentes fatais pode ajudar autoridades, companhias aéreas e órgãos reguladores a tomar medidas preventivas e salvar vidas.\n",
    "\n",
    "Este projeto foca em analisar dados históricos de acidentes aéreos no Brasil (CENIPA) para construir um modelo preditivo capaz de determinar se um acidente será fatal ou não-fatal com base em características do voo, aeronave e condições do acidente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f0a3f2",
   "metadata": {},
   "source": [
    "### 1.2 Objetivos da Análise\n",
    "\n",
    "- **1.** **Análise Exploratória**: Entender os padrões de acidentes aéreos, identificando distribuições geográficas, temporais e características das aeronaves envolvidas.\n",
    "- **2.** **Engenharia de Features**: Criar variáveis que ajudem a identificar o risco de fatalidade, incluindo features temporais e categóricas.\n",
    "- **3.** **Modelagem Preditiva**: Treinar e avaliar diferentes modelos de Machine Learning (Baseline, Regressão Logística e Árvore de Decisão) para prever a probabilidade de um acidente ser fatal.\n",
    "- **4.** **Validação**: Avaliar os modelos usando múltiplas métricas (Acurácia, Precisão, Recall, F1-Score, AUC-ROC) e otimizar o threshold de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f893dc2",
   "metadata": {},
   "source": [
    "### 1.3 Dicionário de Variáveis\n",
    "\n",
    "O conjunto de dados contém informações sobre acidentes aéreos no Brasil. As principais variáveis incluem:\n",
    "\n",
    "**Variáveis Geográficas:**\n",
    "- **latitude/longitude**: Coordenadas do local do acidente\n",
    "- **regiao**: Região do Brasil (Norte, Sul, Nordeste, etc.)\n",
    "- **uf**: Unidade Federativa\n",
    "\n",
    "**Variáveis Temporais:**\n",
    "- **dt_ocorrencia**: Data do acidente\n",
    "- **hr_ocorrencia**: Hora do acidente\n",
    "- **ano_ocorrencia**: Ano extraído da data\n",
    "- **mes_ocorrencia**: Mês extraído da data\n",
    "\n",
    "**Características da Aeronave:**\n",
    "- **modelo_aeronave**: Modelo da aeronave\n",
    "- **nome_fabricante**: Fabricante da aeronave\n",
    "- **cat_aeronave**: Categoria da aeronave\n",
    "- **peso_max_decolagem**: Peso máximo de decolagem\n",
    "- **numero_assentos**: Número de assentos\n",
    "\n",
    "**Variáveis Operacionais:**\n",
    "- **fase_operacao**: Fase do voo (decolagem, cruzeiro, pouso, etc.)\n",
    "- **op_padronizado**: Operação padronizada\n",
    "\n",
    "**Variável Target:**\n",
    "- **les_fatais_trip**: 1 = Fatal, 0 = Não Fatal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898e614",
   "metadata": {},
   "source": [
    "## 2. Configuração do Ambiente\n",
    "\n",
    "Nesta seção, importamos todas as bibliotecas necessárias para a análise, pré-processamento e modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8eb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para manipulação e análise de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Bibliotecas para visualização de dados\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas de Machine Learning e pré-processamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "# Balanceamento de classes\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Configurações de visualização\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44903ac",
   "metadata": {},
   "source": [
    "## 3. Carga e Análise Inicial dos Dados\n",
    "\n",
    "Carregamos os dados de treino e realizamos uma verificação inicial para entender sua estrutura, tipos de dados e a presença de valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa72bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento do dataset de treino\n",
    "df = pd.read_csv(\"docs/treino.csv\")\n",
    "\n",
    "print(f\"✓ Dados carregados com sucesso!\")\n",
    "print(f\"Dimensões: {df.shape[0]} linhas x {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96530d5d",
   "metadata": {},
   "source": [
    "### Análise Inicial:\n",
    "- O dataset possui múltiplas linhas e colunas com informações sobre acidentes aéreos\n",
    "- Há colunas geográficas (latitude, longitude, regiao, uf)\n",
    "- Colunas temporais (dt_ocorrencia, hr_ocorrencia)\n",
    "- Características das aeronaves (modelo, fabricante, peso, assentos)\n",
    "- Variável target: les_fatais_trip (0 = Não Fatal, 1 = Fatal)\n",
    "- Presença de valores nulos que precisarão de tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostra dos dados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85b26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a estrutura e os tipos de dados do DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092fd2a4",
   "metadata": {},
   "source": [
    "## 4. Limpeza e Pré-Processamento dos Dados\n",
    "\n",
    "Esta etapa é crucial para garantir a qualidade dos dados que alimentarão o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d38616",
   "metadata": {},
   "source": [
    "### 4.1 Remoção de Duplicatas\n",
    "\n",
    "Removemos registros duplicados que podem distorcer a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ab8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando informações antes da remoção\n",
    "print(\"Antes da remoção de duplicatas:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo duplicatas\n",
    "linhas_antes = len(df)\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "linhas_depois = len(df)\n",
    "\n",
    "print(f\"Linhas antes: {linhas_antes}\")\n",
    "print(f\"Linhas depois: {linhas_depois}\")\n",
    "print(f\"✓ Duplicatas removidas: {linhas_antes - linhas_depois}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3297f6",
   "metadata": {},
   "source": [
    "### 4.2 Tratamento de Tipos de Dados\n",
    "\n",
    "Convertemos colunas para os tipos apropriados (datas, numéricos, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter latitude e longitude para float\n",
    "df['latitude'] = df['latitude'].astype(str).str.replace(',', '.').astype(float)\n",
    "df['longitude'] = df['longitude'].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "# Converter data\n",
    "df['dt_ocorrencia'] = pd.to_datetime(df['dt_ocorrencia'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "print(\"Conversões realizadas!\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef4841",
   "metadata": {},
   "source": [
    "### 4.3 Tratamento de Valores Ausentes (Nulos)\n",
    "\n",
    "- **Preenchimento com mediana**: Para colunas numéricas\n",
    "- **Preenchimento com moda**: Para colunas categóricas\n",
    "- **Remoção de linhas**: Para dados essenciais ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff948518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preencher valores ausentes - numéricos com mediana\n",
    "df['peso_max_decolagem'].fillna(df['peso_max_decolagem'].median(), inplace=True)\n",
    "df['numero_assentos'].fillna(df['numero_assentos'].median(), inplace=True)\n",
    "\n",
    "# Preencher valores ausentes - categóricos com moda\n",
    "df['op_padronizado'].fillna(df['op_padronizado'].mode()[0], inplace=True)\n",
    "df['hr_ocorrencia'].fillna(df['hr_ocorrencia'].mode()[0], inplace=True)\n",
    "df['regiao'].fillna(df['regiao'].mode()[0], inplace=True)\n",
    "df['fase_operacao'].fillna(df['fase_operacao'].mode()[0], inplace=True)\n",
    "df['modelo_aeronave'].fillna(df['modelo_aeronave'].mode()[0], inplace=True)\n",
    "df['nome_fabricante'].fillna(df['nome_fabricante'].mode()[0], inplace=True)\n",
    "\n",
    "# Remover linhas com dados essenciais ausentes\n",
    "df.dropna(subset=['dt_ocorrencia', 'latitude', 'longitude'], inplace=True)\n",
    "\n",
    "print(\"Tratamento de valores ausentes concluído!\")\n",
    "print(f\"Total de linhas após tratamento: {len(df)}\")\n",
    "print(\"\\nValores nulos restantes:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar novas colunas de ano e mês\n",
    "df['ano_ocorrencia'] = df['dt_ocorrencia'].dt.year\n",
    "df['mes_ocorrencia'] = df['dt_ocorrencia'].dt.month\n",
    "\n",
    "print(\"Novas colunas criadas!\")\n",
    "df[['dt_ocorrencia', 'ano_ocorrencia', 'mes_ocorrencia']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento dos valores (NaN)\n",
    "\n",
    "print(\"\\n--- Contagem de valores nulos ANTES do tratamento ---\")\n",
    "\n",
    "\n",
    "# Lista de colunas numéricas para imputar com a mediana\n",
    "colunas_numericas_nan = ['peso_max_decolagem', 'numero_assentos']\n",
    "for col in colunas_numericas_nan:\n",
    "    mediana = df[col].median()\n",
    "    df[col] = df[col].fillna(mediana)\n",
    "    print(f\"Valores nulos em '{col}' preenchidos com a mediana: {mediana}\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Lista de colunas categóricas para imputar com a moda\n",
    "colunas_categoricas_nan = ['op_padronizado', 'hr_ocorrencia', 'regiao', 'fase_operacao', 'modelo_aeronave', 'nome_fabricante']\n",
    "for col in colunas_categoricas_nan:\n",
    "    moda = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(moda)\n",
    "    print(f\"Valores nulos em '{col}' preenchidos com a moda: '{moda}'\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Removendo linhas onde dados essenciais ainda são nulos\n",
    "print(\"Removendo linhas onde 'dt_ocorrencia', 'latitude' ou 'longitude' são nulos...\")\n",
    "df.dropna(subset=['dt_ocorrencia', 'latitude', 'longitude'], inplace=True)\n",
    "\n",
    "print(\"\\n--- Contagem de valores nulos DEPOIS do tratamento ---\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12316300",
   "metadata": {},
   "source": [
    "## 5. Análise Exploratória de Dados (EDA)\n",
    "\n",
    "### 5.1 Seleção de Features e Visualização da Distribuição da Variável Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar features e target\n",
    "features = ['latitude', 'longitude', 'peso_max_decolagem', 'numero_assentos',\n",
    "            'fase_operacao', 'cat_aeronave', 'regiao', 'uf', 'modelo_aeronave', \n",
    "            'nome_fabricante', 'ano_ocorrencia', 'mes_ocorrencia']\n",
    "\n",
    "X = df[features]\n",
    "y = df['les_fatais_trip']\n",
    "\n",
    "print(f\"Features selecionadas: {X.shape[1]}\")\n",
    "print(f\"Total de registros: {X.shape[0]}\")\n",
    "\n",
    "# Verificar balanceamento\n",
    "print(\"\\nDistribuição da variável target:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Visualizar balanceamento\n",
    "plt.figure(figsize=(8, 5))\n",
    "y.value_counts().plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Acidentes Fatais vs Não Fatais')\n",
    "plt.xlabel('Classe (0=Não Fatal, 1=Fatal)')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af12f2f",
   "metadata": {},
   "source": [
    "## 6. Engenharia e Seleção de Features\n",
    "\n",
    "### 6.1 Divisão dos Dados (Treino/Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treino: {len(X_train)} linhas\")\n",
    "print(f\"Conjunto de teste: {len(X_test)} linhas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bac136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar colunas numéricas e categóricas\n",
    "colunas_numericas = ['latitude', 'longitude', 'peso_max_decolagem', 'numero_assentos', \n",
    "                     'ano_ocorrencia', 'mes_ocorrencia']\n",
    "colunas_categoricas = ['fase_operacao', 'cat_aeronave', 'regiao', 'uf', \n",
    "                       'modelo_aeronave', 'nome_fabricante']\n",
    "\n",
    "print(\"Colunas numéricas:\", colunas_numericas)\n",
    "print(\"Colunas categóricas:\", colunas_categoricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e632fd1a",
   "metadata": {},
   "source": [
    "### 6.2 Separação de Features por Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar variáveis categóricas com get_dummies\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=colunas_categoricas)\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=colunas_categoricas)\n",
    "\n",
    "# Garantir que treino e teste tenham as mesmas colunas\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "print(f\"Features após encoding: {X_train_encoded.shape[1]}\")\n",
    "\n",
    "# Normalizar features numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "print(\"Pré-processamento concluído!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f3df6",
   "metadata": {},
   "source": [
    "### 6.3 Encoding e Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbc032",
   "metadata": {},
   "source": [
    "## 7. Modelagem\n",
    "\n",
    "### 7.1 Balanceamento de Classes com SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dee68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar SMOTE para balancear as classes\n",
    "print(\"Antes do SMOTE:\")\n",
    "print(f\"Classe 0 (Não Fatal): {sum(y_train == 0)}\")\n",
    "print(f\"Classe 1 (Fatal): {sum(y_train == 1)}\")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nDepois do SMOTE:\")\n",
    "print(f\"Classe 0 (Não Fatal): {sum(y_train_balanced == 0)}\")\n",
    "print(f\"Classe 1 (Fatal): {sum(y_train_balanced == 1)}\")\n",
    "\n",
    "# Visualizar balanceamento\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "pd.Series(y_train).value_counts().plot(kind='bar', ax=axes[0], color=['skyblue', 'salmon'])\n",
    "axes[0].set_title('Antes do SMOTE')\n",
    "axes[0].set_xlabel('Classe')\n",
    "axes[0].set_ylabel('Quantidade')\n",
    "\n",
    "pd.Series(y_train_balanced).value_counts().plot(kind='bar', ax=axes[1], color=['lightgreen', 'lightcoral'])\n",
    "axes[1].set_title('Depois do SMOTE')\n",
    "axes[1].set_xlabel('Classe')\n",
    "axes[1].set_ylabel('Quantidade')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95129ad",
   "metadata": {},
   "source": [
    "### 7.2 Treinamento dos Modelos\n",
    "\n",
    "Treinamos três modelos para comparação:\n",
    "- **Baseline (Dummy)**: Modelo simples de referência\n",
    "- **Regressão Logística**: Modelo linear com dados balanceados\n",
    "- **Árvore de Decisão**: Modelo não-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar os modelos\n",
    "\n",
    "# 1. Modelo Baseline (Dummy)\n",
    "modelo_baseline = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "modelo_baseline.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 2. Regressão Logística com dados balanceados\n",
    "modelo_logistica = LogisticRegression(random_state=42, max_iter=1000)\n",
    "modelo_logistica.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# 3. Árvore de Decisão\n",
    "modelo_arvore = DecisionTreeClassifier(random_state=42)\n",
    "modelo_arvore.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Modelos treinados com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer predições\n",
    "y_pred_baseline = modelo_baseline.predict(X_test_scaled)\n",
    "y_pred_logistica = modelo_logistica.predict(X_test_scaled)\n",
    "y_pred_arvore = modelo_arvore.predict(X_test_scaled)\n",
    "\n",
    "# Calcular métricas para cada modelo\n",
    "modelos = ['Baseline', 'Regressão Logística', 'Árvore de Decisão']\n",
    "predicoes = [y_pred_baseline, y_pred_logistica, y_pred_arvore]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESULTADOS DOS MODELOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for nome, y_pred in zip(modelos, predicoes):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{nome}:\")\n",
    "    print(f\"  Acurácia:  {acc:.4f}\")\n",
    "    print(f\"  Precisão:  {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279a8b0",
   "metadata": {},
   "source": [
    "### 7.3 Predições e Métricas Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf90f9d",
   "metadata": {},
   "source": [
    "## 8. Validação e Comparação dos Modelos\n",
    "\n",
    "### 8.1 Matrizes de Confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27489b05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41177aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusão - Regressão Logística\n",
    "print(\"Matriz de Confusão - Regressão Logística\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logistica, cmap='Blues')\n",
    "plt.title('Matriz de Confusão - Regressão Logística')\n",
    "plt.show()\n",
    "\n",
    "# Matriz de Confusão - Árvore de Decisão\n",
    "print(\"\\nMatriz de Confusão - Árvore de Decisão\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_arvore, cmap='Greens')\n",
    "plt.title('Matriz de Confusão - Árvore de Decisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a751c7",
   "metadata": {},
   "source": [
    "As matrizes de confusão mostram os acertos e erros de cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Calcular AUC para cada modelo\n",
    "auc_logistica = roc_auc_score(y_test, modelo_logistica.predict_proba(X_test_scaled)[:, 1])\n",
    "auc_arvore = roc_auc_score(y_test, modelo_arvore.predict_proba(X_test_scaled)[:, 1])\n",
    "\n",
    "# Plotar curvas\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    modelo_logistica.predict_proba(X_test_scaled)[:, 1], \n",
    "    name=f'Regressão Logística (AUC = {auc_logistica:.3f})', \n",
    "    ax=ax,\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    modelo_arvore.predict_proba(X_test_scaled)[:, 1], \n",
    "    name=f'Árvore de Decisão (AUC = {auc_arvore:.3f})', \n",
    "    ax=ax,\n",
    "    color='green'\n",
    ")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='red', label='Aleatório (AUC = 0.5)')\n",
    "plt.title('Curva ROC - Comparação dos Modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC Regressão Logística: {auc_logistica:.3f}\")\n",
    "print(f\"AUC Árvore de Decisão: {auc_arvore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c34421",
   "metadata": {},
   "source": [
    "### 8.2 Curva ROC e AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca1505",
   "metadata": {},
   "source": [
    "## 9. Otimização e Avaliação Final\n",
    "\n",
    "### 9.1 Análise de Threshold (Limiar de Decisão)\n",
    "\n",
    "Por padrão, o modelo usa threshold de 0.5 para classificar. Vamos testar diferentes thresholds para otimizar o F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo as probabilidades de predição\n",
    "y_proba = modelo_logistica.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"Testando diferentes thresholds de 0.0 a 1.0...\")\n",
    "\n",
    "# Testando diferentes thresholds\n",
    "thresholds_results = {\n",
    "    'threshold': [],\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "\n",
    "for threshold in np.arange(0.0, 1.01, 0.01):\n",
    "    # Aplicando o threshold customizado\n",
    "    y_pred_threshold = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Calculando as métricas\n",
    "    acc = accuracy_score(y_test, y_pred_threshold)\n",
    "    prec = precision_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_threshold, zero_division=0)\n",
    "    \n",
    "    # Armazenando os resultados\n",
    "    thresholds_results['threshold'].append(threshold)\n",
    "    thresholds_results['accuracy'].append(acc)\n",
    "    thresholds_results['precision'].append(prec)\n",
    "    thresholds_results['recall'].append(rec)\n",
    "    thresholds_results['f1_score'].append(f1)\n",
    "\n",
    "# Convertendo para DataFrame\n",
    "df_thresholds = pd.DataFrame(thresholds_results)\n",
    "\n",
    "# Encontrando o melhor threshold baseado no F1-Score\n",
    "melhor_threshold_idx = df_thresholds['f1_score'].idxmax()\n",
    "melhor_threshold = df_thresholds.loc[melhor_threshold_idx, 'threshold']\n",
    "melhor_f1 = df_thresholds.loc[melhor_threshold_idx, 'f1_score']\n",
    "\n",
    "print(f\"\\nMelhor threshold encontrado: {melhor_threshold:.2f}\")\n",
    "print(f\"F1-Score: {melhor_f1:.4f}\")\n",
    "print(f\"Accuracy: {df_thresholds.loc[melhor_threshold_idx, 'accuracy']:.4f}\")\n",
    "print(f\"Precision: {df_thresholds.loc[melhor_threshold_idx, 'precision']:.4f}\")\n",
    "print(f\"Recall: {df_thresholds.loc[melhor_threshold_idx, 'recall']:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 5 melhores thresholds por F1-Score:\")\n",
    "print(df_thresholds.nlargest(5, 'f1_score')[['threshold', 'f1_score', 'accuracy', 'precision', 'recall']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3482af4",
   "metadata": {},
   "source": [
    "### 9.2 Visualização do Impacto do Threshold\n",
    "\n",
    "Vamos visualizar graficamente como o threshold afeta as diferentes métricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfe03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o gráfico de impacto do threshold\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plotando as curvas de métricas\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['accuracy'], \n",
    "         label='Acurácia', linewidth=2, color='blue', alpha=0.7)\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['precision'], \n",
    "         label='Precisão', linewidth=2, color='green', alpha=0.7)\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['recall'], \n",
    "         label='Recall', linewidth=2, color='orange', alpha=0.7)\n",
    "plt.plot(df_thresholds['threshold'], df_thresholds['f1_score'], \n",
    "         label='F1-Score', linewidth=2.5, color='red', alpha=0.9)\n",
    "\n",
    "# Marcando o melhor threshold\n",
    "plt.axvline(x=melhor_threshold, color='purple', linestyle='--', linewidth=2, \n",
    "            label=f'Melhor Threshold ({melhor_threshold:.2f})')\n",
    "plt.scatter([melhor_threshold], [melhor_f1], color='purple', s=200, zorder=5, \n",
    "            marker='*', edgecolors='black', linewidths=1.5)\n",
    "\n",
    "# Configurações do gráfico\n",
    "plt.xlabel('Threshold (Limiar de Decisão)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Score das Métricas', fontsize=12, fontweight='bold')\n",
    "plt.title('Impacto do Threshold nas Métricas de Avaliação\\n(Trade-off entre Precisão e Recall)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretação dos resultados\n",
    "print(\"\\n📖 INTERPRETAÇÃO DO GRÁFICO:\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. PRECISÃO (linha verde):\")\n",
    "print(\"   - Aumenta conforme o threshold aumenta\")\n",
    "print(\"   - Threshold alto = menos falsos positivos = maior precisão\")\n",
    "print(\"   - Use threshold alto quando o custo de falsos positivos é alto\")\n",
    "\n",
    "print(\"\\n2. RECALL (linha laranja):\")\n",
    "print(\"   - Diminui conforme o threshold aumenta\")\n",
    "print(\"   - Threshold baixo = menos falsos negativos = maior recall\")\n",
    "print(\"   - Use threshold baixo quando o custo de falsos negativos é alto\")\n",
    "\n",
    "print(\"\\n3. F1-SCORE (linha vermelha - MAIS IMPORTANTE):\")\n",
    "print(\"   - Equilibra Precisão e Recall\")\n",
    "print(f\"   - Pico em threshold = {melhor_threshold:.2f}\")\n",
    "print(\"   - É o melhor ponto de equilíbrio entre as duas métricas\")\n",
    "\n",
    "print(\"\\n4. TRADE-OFF:\")\n",
    "print(\"   - O gráfico mostra claramente o trade-off entre Precisão e Recall\")\n",
    "print(\"   - Não podemos maximizar ambos simultaneamente\")\n",
    "print(f\"   - O threshold ótimo ({melhor_threshold:.2f}) balanceia ambos\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13e9af",
   "metadata": {},
   "source": [
    "### 9.3 Comparação Final dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e0799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando threshold otimizado\n",
    "y_pred_logistica_threshold = (y_proba >= melhor_threshold).astype(int)\n",
    "\n",
    "# Comparando métricas dos modelos\n",
    "metricas = {\n",
    "    'Modelo': ['Baseline (Dummy)', 'Regressão Logística', 'Árvore de Decisão'],\n",
    "    'Acurácia': [\n",
    "        accuracy_score(y_test, y_pred_baseline), \n",
    "        accuracy_score(y_test, y_pred_logistica_threshold),\n",
    "        accuracy_score(y_test, y_pred_arvore)\n",
    "    ],\n",
    "    'Precisão': [\n",
    "        precision_score(y_test, y_pred_baseline, zero_division=0), \n",
    "        precision_score(y_test, y_pred_logistica_threshold, zero_division=0),\n",
    "        precision_score(y_test, y_pred_arvore, zero_division=0)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_baseline, zero_division=0), \n",
    "        recall_score(y_test, y_pred_logistica_threshold, zero_division=0),\n",
    "        recall_score(y_test, y_pred_arvore, zero_division=0)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_test, y_pred_baseline, zero_division=0), \n",
    "        f1_score(y_test, y_pred_logistica_threshold, zero_division=0),\n",
    "        f1_score(y_test, y_pred_arvore, zero_division=0)\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metricas = pd.DataFrame(metricas)\n",
    "\n",
    "# Mostrando resultados\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARAÇÃO DE MÉTRICAS DOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(df_metricas)\n",
    "\n",
    "# Encontrando o melhor modelo por F1-Score\n",
    "melhor_modelo_idx = df_metricas['F1-Score'].idxmax()\n",
    "print(f\"\\nMELHOR MODELO: {df_metricas.loc[melhor_modelo_idx, 'Modelo']}\")\n",
    "print(f\"F1-Score: {df_metricas.loc[melhor_modelo_idx, 'F1-Score']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Matriz de Confusão - Regressão Logística\n",
    "print(\"\\nMatriz de Confusão: Regressão Logística\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_logistica_threshold, cmap='Blues')\n",
    "plt.title(f'Matriz de Confusão - Regressão Logística\\n(Threshold = {melhor_threshold:.2f})')\n",
    "plt.show()\n",
    "\n",
    "# Matriz de Confusão - Árvore de Decisão\n",
    "print(\"\\nMatriz de Confusão: Árvore de Decisão\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_arvore, cmap='Greens')\n",
    "plt.title('Matriz de Confusão - Árvore de Decisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo probabilidades\n",
    "y_proba_logistica = modelo_logistica.predict_proba(X_test_scaled)[:, 1]\n",
    "y_proba_arvore = modelo_arvore.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculando AUC\n",
    "auc_logistica = roc_auc_score(y_test, y_proba_logistica)\n",
    "auc_arvore = roc_auc_score(y_test, y_proba_arvore)\n",
    "\n",
    "# Plotando as curvas ROC\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    y_proba_logistica, \n",
    "    name=f'Regressão Logística (AUC = {auc_logistica:.3f})', \n",
    "    ax=ax,\n",
    "    color='blue',\n",
    "    linewidth=2.5\n",
    ")\n",
    "\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_test, \n",
    "    y_proba_arvore, \n",
    "    name=f'Árvore de Decisão (AUC = {auc_arvore:.3f})', \n",
    "    ax=ax,\n",
    "    color='green',\n",
    "    linewidth=2\n",
    ")\n",
    "\n",
    "# Linha de referência\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', color='red', label='Classificador Aleatório (AUC = 0.5)', linewidth=2)\n",
    "\n",
    "plt.title('Curva ROC - Comparação dos Modelos', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nINTERPRETAÇÃO DA CURVA ROC:\")\n",
    "print(\"- AUC próximo de 1.0: Modelo excelente\")\n",
    "print(\"- AUC próximo de 0.5: Modelo aleatório\")\n",
    "print(f\"- Regressão Logística: {auc_logistica:.3f}\")\n",
    "print(f\"- Árvore de Decisão: {auc_arvore:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be43d7bf",
   "metadata": {},
   "source": [
    "### 9.4 Análise Exploratória - Distribuição Geográfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea40c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização Geográfica dos Acidentes\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Gráfico 1: Mapa de dispersão de todos os acidentes\n",
    "scatter1 = axes[0].scatter(\n",
    "    df['longitude'], \n",
    "    df['latitude'], \n",
    "    c=df['les_fatais_trip'],\n",
    "    cmap='RdYlGn_r',  # Vermelho (fatal) para Verde (não-fatal)\n",
    "    alpha=0.6,\n",
    "    s=50,\n",
    "    edgecolors='black',\n",
    "    linewidth=0.5\n",
    ")\n",
    "axes[0].set_xlabel('Longitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Latitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('🗺️ Distribuição Geográfica dos Acidentes Aéreos\\n(Brasil)', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionar legenda\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label('Fatalidade (0=Não Fatal, 1=Fatal)', rotation=270, labelpad=20)\n",
    "\n",
    "# Gráfico 2: Acidentes por Região\n",
    "acidentes_por_regiao = df.groupby(['regiao', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_por_regiao.plot(kind='bar', ax=axes[1], color=['lightgreen', 'crimson'], width=0.7)\n",
    "axes[1].set_xlabel('Região', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Número de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('📍 Acidentes por Região e Gravidade', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(['Não Fatal', 'Fatal'], loc='upper right')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estatísticas geográficas\n",
    "print(\"\\n📊 ESTATÍSTICAS GEOGRÁFICAS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n🗺️ Total de acidentes: {len(df)}\")\n",
    "print(f\"\\n📍 Acidentes por região:\")\n",
    "for regiao in df['regiao'].value_counts().index:\n",
    "    total = len(df[df['regiao'] == regiao])\n",
    "    fatais = len(df[(df['regiao'] == regiao) & (df['les_fatais_trip'] == 1)])\n",
    "    taxa = (fatais/total)*100 if total > 0 else 0\n",
    "    print(f\"   {regiao}: {total} acidentes ({fatais} fatais - {taxa:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise Temporal dos Acidentes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Gráfico 1: Acidentes por Ano\n",
    "acidentes_ano = df.groupby(['ano_ocorrencia', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_ano.plot(kind='bar', ax=axes[0, 0], color=['lightgreen', 'crimson'], width=0.8)\n",
    "axes[0, 0].set_xlabel('Ano', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Número de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('📊 Acidentes por Ano', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(['Não Fatal', 'Fatal'], loc='upper right')\n",
    "axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45, ha='right')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Tendência de Acidentes Fatais\n",
    "acidentes_fatais_ano = df[df['les_fatais_trip'] == 1].groupby('ano_ocorrencia').size()\n",
    "acidentes_totais_ano = df.groupby('ano_ocorrencia').size()\n",
    "taxa_fatalidade = (acidentes_fatais_ano / acidentes_totais_ano * 100).fillna(0)\n",
    "\n",
    "axes[0, 1].plot(taxa_fatalidade.index, taxa_fatalidade.values, marker='o', \n",
    "                linewidth=3, markersize=8, color='darkred')\n",
    "axes[0, 1].fill_between(taxa_fatalidade.index, taxa_fatalidade.values, alpha=0.3, color='red')\n",
    "axes[0, 1].set_xlabel('Ano', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Taxa de Fatalidade (%)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('📈 Tendência da Taxa de Fatalidade ao Longo dos Anos', \n",
    "                      fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Gráfico 3: Acidentes por Mês\n",
    "acidentes_mes = df.groupby(['mes_ocorrencia', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_mes.plot(kind='bar', ax=axes[1, 0], color=['lightgreen', 'crimson'], width=0.8)\n",
    "axes[1, 0].set_xlabel('Mês', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Número de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('📆 Acidentes por Mês (Sazonalidade)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(['Não Fatal', 'Fatal'], loc='upper right')\n",
    "meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez']\n",
    "axes[1, 0].set_xticklabels(meses, rotation=45, ha='right')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Gráfico 4: Acidentes por Fase de Operação\n",
    "acidentes_fase = df.groupby(['fase_operacao', 'les_fatais_trip']).size().unstack(fill_value=0)\n",
    "acidentes_fase = acidentes_fase.nlargest(10, 1)  # Top 10 fases com mais fatais\n",
    "acidentes_fase.plot(kind='barh', ax=axes[1, 1], color=['lightgreen', 'crimson'])\n",
    "axes[1, 1].set_xlabel('Número de Acidentes', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Fase de Operação', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('✈️ Top 10 Fases de Operação Mais Críticas', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend(['Não Fatal', 'Fatal'], loc='lower right')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estatísticas temporais\n",
    "print(\"\\n📊 ESTATÍSTICAS TEMPORAIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n📅 Período analisado: {df['ano_ocorrencia'].min()} - {df['ano_ocorrencia'].max()}\")\n",
    "print(f\"\\n📈 Taxa média de fatalidade: {taxa_fatalidade.mean():.2f}%\")\n",
    "print(f\"\\n🔴 Ano com maior taxa de fatalidade: {taxa_fatalidade.idxmax()} ({taxa_fatalidade.max():.2f}%)\")\n",
    "print(f\"🟢 Ano com menor taxa de fatalidade: {taxa_fatalidade.idxmin()} ({taxa_fatalidade.min():.2f}%)\")\n",
    "print(f\"\\n📆 Mês com mais acidentes: {meses[acidentes_mes.sum(axis=1).idxmax()-1]}\")\n",
    "print(f\"📆 Mês com menos acidentes: {meses[acidentes_mes.sum(axis=1).idxmin()-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398af7f",
   "metadata": {},
   "source": [
    "### 9.5 Análise Exploratória - Padrões Temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e451d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparação Visual dos Modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Preparar dados para visualização\n",
    "modelos_nomes = ['Baseline\\n(Dummy)', 'Regressão\\nLogística', 'Árvore de\\nDecisão']\n",
    "cores_modelos = ['gray', 'green', 'orange']\n",
    "\n",
    "# Gráfico 1: Comparação de Acurácia\n",
    "acuracias = df_metricas['Acurácia'].values\n",
    "bars1 = axes[0, 0].bar(range(len(modelos_nomes)), acuracias, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_ylabel('Acurácia', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Acurácia dos Modelos', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(range(len(modelos_nomes)))\n",
    "axes[0, 0].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[0, 0].set_ylim([0, 1])\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{acuracias[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico 2: Comparação de Precisão\n",
    "precisoes = df_metricas['Precisão'].values\n",
    "bars2 = axes[0, 1].bar(range(len(modelos_nomes)), precisoes, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[0, 1].set_ylabel('Precisão', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Precisão dos Modelos', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(range(len(modelos_nomes)))\n",
    "axes[0, 1].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[0, 1].set_ylim([0, 1])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{precisoes[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico 3: Comparação de Recall\n",
    "recalls = df_metricas['Recall'].values\n",
    "bars3 = axes[1, 0].bar(range(len(modelos_nomes)), recalls, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 0].set_ylabel('Recall', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('Recall dos Modelos', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(range(len(modelos_nomes)))\n",
    "axes[1, 0].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[1, 0].set_ylim([0, 1])\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars3):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{recalls[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Gráfico 4: Comparação de F1-Score\n",
    "f1_scores = df_metricas['F1-Score'].values\n",
    "bars4 = axes[1, 1].bar(range(len(modelos_nomes)), f1_scores, color=cores_modelos, edgecolor='black', linewidth=1.5)\n",
    "axes[1, 1].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('F1-Score dos Modelos (MÉTRICA PRINCIPAL)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xticks(range(len(modelos_nomes)))\n",
    "axes[1, 1].set_xticklabels(modelos_nomes, fontsize=9)\n",
    "axes[1, 1].set_ylim([0, 1])\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "for i, bar in enumerate(bars4):\n",
    "    height = bar.get_height()\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{f1_scores[i]:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    # Destacar o melhor modelo\n",
    "    if i == melhor_modelo_idx:\n",
    "        bar.set_edgecolor('gold')\n",
    "        bar.set_linewidth(4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo estatístico\n",
    "print(\"\\nRANKING DOS MODELOS (por F1-Score)\")\n",
    "print(\"=\"*70)\n",
    "ranking = df_metricas.sort_values('F1-Score', ascending=False)\n",
    "for idx, row in ranking.iterrows():\n",
    "    emoji = \"1º\" if idx == 0 else \"2º\" if idx == 1 else \"3º\"\n",
    "    print(f\"{emoji} {row['Modelo']}\")\n",
    "    print(f\"   F1-Score: {row['F1-Score']:.4f} | Acurácia: {row['Acurácia']:.4f} | \"\n",
    "          f\"Precisão: {row['Precisão']:.4f} | Recall: {row['Recall']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543b9fa",
   "metadata": {},
   "source": [
    "### 9.6 Comparação Visual dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise de Importância das Features\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Gráfico 1: Importância das Features - Regressão Logística\n",
    "# Usar coeficientes do modelo de Regressão Logística\n",
    "feature_names_encoded = X_train_encoded.columns.tolist()\n",
    "coeficientes = modelo_logistica.coef_[0]\n",
    "\n",
    "# Criar DataFrame com importâncias\n",
    "importancias_log_df = pd.DataFrame({\n",
    "    'Feature': feature_names_encoded,\n",
    "    'Importância': np.abs(coeficientes)  # Valor absoluto para ranking\n",
    "}).sort_values('Importância', ascending=False).head(15)\n",
    "\n",
    "# Plotar\n",
    "axes[0].barh(range(len(importancias_log_df)), importancias_log_df['Importância'], \n",
    "             color='green', edgecolor='black')\n",
    "axes[0].set_yticks(range(len(importancias_log_df)))\n",
    "axes[0].set_yticklabels(importancias_log_df['Feature'], fontsize=9)\n",
    "axes[0].set_xlabel('Importância Absoluta (|Coeficiente|)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Top 15 Features - Regressão Logística', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Gráfico 2: Importância das Features - Árvore de Decisão\n",
    "importancias_arvore = modelo_arvore.feature_importances_\n",
    "\n",
    "importancias_arvore_df = pd.DataFrame({\n",
    "    'Feature': feature_names_encoded,\n",
    "    'Importância': importancias_arvore\n",
    "}).sort_values('Importância', ascending=False).head(15)\n",
    "\n",
    "axes[1].barh(range(len(importancias_arvore_df)), importancias_arvore_df['Importância'], \n",
    "             color='orange', edgecolor='black')\n",
    "axes[1].set_yticks(range(len(importancias_arvore_df)))\n",
    "axes[1].set_yticklabels(importancias_arvore_df['Feature'], fontsize=9)\n",
    "axes[1].set_xlabel('Importância (Gini)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Top 15 Features - Árvore de Decisão', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Resumo das features mais importantes\n",
    "print(\"\\nFEATURES MAIS IMPORTANTES\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nRegressão Logística (Top 5):\")\n",
    "for idx, row in importancias_log_df.head(5).iterrows():\n",
    "    print(f\"   {row['Feature']}: {row['Importância']:.4f}\")\n",
    "\n",
    "print(\"\\nÁrvore de Decisão (Top 5):\")\n",
    "for idx, row in importancias_arvore_df.head(5).iterrows():\n",
    "    print(f\"   {row['Feature']}: {row['Importância']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a36e32",
   "metadata": {},
   "source": [
    "### 9.7 Importância das Features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
